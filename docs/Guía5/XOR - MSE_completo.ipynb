{"cells":[{"cell_type":"markdown","id":"14bdfc16-bd96-4d61-bd25-dfe041304734","metadata":{"tags":[],"id":"14bdfc16-bd96-4d61-bd25-dfe041304734"},"source":["# CARGA DE BIBLIOTECAS"]},{"cell_type":"code","execution_count":null,"id":"8e3f748c-3008-42c6-9052-f20045f074b0","metadata":{"tags":[],"id":"8e3f748c-3008-42c6-9052-f20045f074b0"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from copy import deepcopy\n","\n","import torch\n","from torch import nn  # Modelos neuronales y funciones de Loss\n","\n","from torch import optim # (3er paso del algoritmo de retropropagación) Optimizadores ---> Gradiente descendiente, Adam, AdaDelta, etc\n","from torch.utils.data import Dataset, DataLoader\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # Elige el dispositivo. Utilizará GPU si está disponible"]},{"cell_type":"markdown","id":"9d0ba14b-e9d8-47c6-8ca2-716a5648aad4","metadata":{"tags":[],"id":"9d0ba14b-e9d8-47c6-8ca2-716a5648aad4"},"source":["# CONSTRUCCION DEL DATASET"]},{"cell_type":"code","execution_count":null,"id":"82855b1b-0d03-46c0-b577-b30284903515","metadata":{"tags":[],"id":"82855b1b-0d03-46c0-b577-b30284903515"},"outputs":[],"source":["class dataset(Dataset):\n","    '''\n","    Esta clase maneja la lectura de los datos y provee un mecanismo\n","    para alimentar los modelos con los patrones.\n","    '''\n","\n","    #===================================================\n","    def __init__(self, filename):\n","\n","        #------------------------------------\n","        # LECTURA DE LOS DATOS\n","        data = pd.read_csv(filename, header=None).to_numpy() # Levanta los datos en formato numpy\n","\n","        #------------------------------------\n","        # ALEATORIZO LOS PATRONES (filas)\n","        idxs = np.arange(len(data))  # Genero un vector de índices\n","        np.random.shuffle(idxs)\n","        data = data[idxs,:]\n","\n","        #------------------------------------\n","        # SEPARO LOS DATOS\n","        self.x = data[:,:-1].astype(np.float32)\n","        self.y = data[:,-1].astype(np.float32)  # La clase está en la última columna\n","\n","    #===================================================\n","    def __len__(self):\n","        '''\n","        Devuelve el número de patrones en el dataset.\n","        '''\n","        return len(self.x)\n","\n","\n","    #===================================================\n","    def __getitem__(self, idx):\n","        '''\n","        Devuelve el/los patrones indicados.\n","        '''\n","        return self.x[idx,:], self.y[idx]"]},{"cell_type":"markdown","id":"8e258bf4-a9a2-4e37-b967-be80cfb97bd1","metadata":{"tags":[],"id":"8e258bf4-a9a2-4e37-b967-be80cfb97bd1"},"source":["# CONSTRUCCION DEL MODELO"]},{"cell_type":"markdown","id":"005168df-89e6-4127-ad13-c16b23b84826","metadata":{"tags":[],"id":"005168df-89e6-4127-ad13-c16b23b84826"},"source":["## PERCEPTRON MULTICAPA"]},{"cell_type":"code","execution_count":null,"id":"9a5fe2a2-ed88-44a0-aa31-76924a899133","metadata":{"tags":[],"id":"9a5fe2a2-ed88-44a0-aa31-76924a899133"},"outputs":[],"source":["class model(nn.Module):\n","\n","    #====================================\n","    def __init__(self, n_features, n_inputs, n_outputs):\n","        '''\n","        Esta función inicializa/construye el perceptrón.\n","        n_features: features de cada patrón (2 para OR y XOR)\n","        n_outputs: cantidad de salidas esperadas.\n","        '''\n","\n","        super().__init__()\n","\n","        self.n_features = n_features\n","        self.n_inputs = n_inputs\n","        self.n_outputs = n_outputs\n","\n","        self.layer1 = nn.Linear(self.n_features, self.n_inputs, bias=True)\n","        self.layer2 = nn.Linear(self.n_inputs, self.n_outputs, bias=True)\n","\n","        self.tanh = nn.Tanh()\n","\n","    #====================================\n","    def forward(self, x):\n","        '''\n","        Esta función realiza la pasada hacia adelante.\n","        '''\n","\n","        # Calculo salida lineal de la capa 1\n","        y = self.layer1(x)\n","\n","        # Aplico función no lineal\n","        y = self.tanh(y)\n","\n","        # Calculo salida lineal de la capa 2\n","        y = self.layer2(y)\n","\n","        # Aplico función no lineal\n","        y = self.tanh(y)\n","\n","        return y"]},{"cell_type":"markdown","id":"8485ea4c-eb90-4631-aaa7-f0644433b0c4","metadata":{"tags":[],"id":"8485ea4c-eb90-4631-aaa7-f0644433b0c4"},"source":["# LOOPS"]},{"cell_type":"markdown","id":"0d3f8e61-1a63-4b42-a417-60205e3368a4","metadata":{"tags":[],"id":"0d3f8e61-1a63-4b42-a417-60205e3368a4"},"source":["## ENTRENAMIENTO"]},{"cell_type":"code","execution_count":null,"id":"afa767ee-273e-4e79-b944-0e54b1e48830","metadata":{"id":"afa767ee-273e-4e79-b944-0e54b1e48830","tags":[]},"outputs":[],"source":["def train_step(model, data, loss_function, optimizer, device):\n","    '''\n","    Esta función se encarga de pasar todos los patrones\n","    a través del modelo neuronal y realizar el ajuste de los pesos.\n","    '''\n","\n","    model.train()  # Activamos el cálcula de gradientes\n","\n","    N_batches = len(data)  # Número de batches = N_patrones/N_patrones_x_batch\n","\n","    error = 0\n","\n","    #==============================================================\n","    for idx,(X,y) in enumerate(data):\n","\n","        X = X.to(device)  # Se envían los datos a la GPU (si se dispone)\n","        y = y.to(device)  # Se envían los datos a la GPU (si se dispone)\n","\n","        optimizer.zero_grad()  # Se limpia el caché del optimizador\n","\n","        #-----------------------\n","        # Pasada hacia adelante\n","        # (Forward pass)\n","        #-----------------------\n","        y_pred = model(X)\n","\n","        #---------------------------\n","        # Cálculo del error (Loss)\n","        #---------------------------\n","        if (data.batch_size == 1):\n","            loss = loss_function(y_pred.squeeze(), y.squeeze())  # El método \"squeeze()\" elimina todas las dimensiones con valor \"1\"\n","                                                                 # Ej. el vector [[1,2,3]] tiene dimensiones (1,3). Luego de aplicar\n","                                                                 # \"squeeze()\", el vector resultante [1,2,3] tiene dimensiones (3,)\n","        else:\n","            loss = loss_function(y_pred.squeeze(), y)\n","\n","        error += loss.item()\n","\n","        #-----------------------\n","        # Retropropagación\n","        # (Backward pass)\n","        #-----------------------\n","        loss.backward()\n","        optimizer.step()\n","    #==============================================================\n","\n","    error /= N_batches\n","\n","    return error, model"]},{"cell_type":"markdown","id":"77c55181-cbbb-459d-bdf7-38458fcecd56","metadata":{"id":"77c55181-cbbb-459d-bdf7-38458fcecd56"},"source":["## VALIDACION / TEST"]},{"cell_type":"code","execution_count":null,"id":"cb54b03c-0418-4a6f-8739-718dca662380","metadata":{"id":"cb54b03c-0418-4a6f-8739-718dca662380","tags":[]},"outputs":[],"source":["def predict_step(model, data, loss_function, device):\n","    '''\n","    Esta función se encarga de pasar todos los patrones\n","    hacia adelante a través del modelo para generar\n","    las predicciones.\n","    '''\n","\n","    model.eval()  # Se desactiva el funcionamiento\n","                  # de algunos elementos especiales de PyTorch\n","\n","    N_batches = len(data)  # Número de batches = N_patrones/N_patrones_x_batch\n","\n","    error = 0\n","\n","    Y = torch.tensor([])\n","    Yp = torch.tensor([])\n","\n","    #==============================================================\n","    with torch.no_grad():  # Turn off gradients computation\n","\n","        for idx,(X,y) in enumerate(data):\n","\n","            Y = torch.hstack( (Y, y.flatten()) )  # En esta línea acumulamos las salidas deseadas\n","                                                  # en un único vector, de manera de tener ordenados\n","                                                  # los pares \"salida deseada\" | \"salida predicha\" para\n","                                                  # calcular medidas de desempeño al finalizar esta etapa.\n","                                                  # El método \"flatten()\" genera un vector \"plano\".\n","\n","            X = X.to(device)  # Se envían los datos a la GPU (si se dispone)\n","            y = y.to(device)  # Se envían los datos a la GPU (si se dispone)\n","\n","            #-----------------------\n","            # Pasada hacia adelante\n","            # (Forward pass)\n","            #-----------------------\n","            y_pred = model(X)\n","\n","            Yp = torch.hstack( (Yp, y_pred.flatten().cpu()) )  # En esta línea acumulamos las salidas predichas\n","                                                               # del modelo en un único vector, de manera de tener\n","                                                               # ordenados los pares \"salida deseada\" | \"salida predicha\"\n","                                                               # para calcular medidas de desempeño al finalizar esta etapa.\n","                                                               # El método \"flatten()\" genera un vector \"plano\".\n","                                                               # El método \"cpu()\" retorna los datos a la CPU en caso de estar en la GPU.\n","\n","            #---------------------------\n","            # Cálculo del error (Loss)\n","            #---------------------------\n","            loss = loss_function(y_pred.squeeze(), y.squeeze())  # El método \"squeeze()\" elimina todas las dimensiones con valor \"1\"\n","                                                                 # Ej. el vector [[1,2,3]] tiene dimensiones (1,3). Luego de aplicar\n","                                                                 # \"squeeze()\", el vector resultante [1,2,3] tiene dimensiones (3,)\n","\n","            error += loss.item()\n","    #==============================================================\n","\n","    error /= N_batches\n","\n","    #------------------\n","\n","    return error, Y, Yp"]},{"cell_type":"markdown","id":"cc05240d-d9a7-447a-a825-6463128a5b5c","metadata":{"tags":[],"id":"cc05240d-d9a7-447a-a825-6463128a5b5c"},"source":["# EXPERIMENTO"]},{"cell_type":"code","execution_count":null,"id":"9c8178b0-fdd6-4a49-a44b-ab0e0691e8a3","metadata":{"tags":[],"id":"9c8178b0-fdd6-4a49-a44b-ab0e0691e8a3"},"outputs":[],"source":["#=================================\n","# Definimos los archivos de datos\n","#=================================\n","filename_train_data = 'XOR_trn.csv'\n","filename_validation_data = 'XOR_trn.csv'\n","filename_test_data = 'XOR_tst.csv'\n","\n","\n","#==========================================\n","# Inicializamos parámetros del experimento\n","#==========================================\n","LEARNING_RATE = 1E-3  # tasa de aprendizaje\n","\n","MOMENTUM = 0.9    # Término de momento\n","\n","MAX_EPOCAS = 50   # Defino el número máximo de épocas\n","                  # de entrenamiento.\n","\n","PATIENCE = 10     # Defino el máximo número de épocas\n","                  # sin mejorar el error de validación\n","                  # para detener el entrenamiento.\n","\n","BATCH_SIZE = 10  # Número de patrones en cada batch\n","                 # Se denomina 'batch' a un conjunto de patrones\n","                 # que se procesan juntos durante una pasada a\n","                 # través de la red neuronal  durante el aprendizaje.\n","                 # Ej. si el batch incluye 10 patrones, los mismos\n","                 # son usados para realizar los pasos hacia adelante,\n","                 # la retropropagación y el cálculo de la actualización\n","                 # de los pesos de acuerdo al error cometido con cada patrón.\n","                 # Sin embargo, al usar un batch se combinan las actualizaciones\n","                 # de pesos debidas a cada patrón y se realiza una única\n","                 # actualización \"promedio\".\n","\n","#-----------------------------------------------------\n","\n","acc = 0.  # Inicializo el accuracy inicial\n","epoca = 0  # Inicializo contador de épocas\n","MIN_ERROR = 1E6   # Inicializo la variable para\n","                  # registrar el mínimo error cometido.\n","\n","\n","#===========================================================\n","# Construimos los datasets para entrenamiento y validación\n","#===========================================================\n","trn = dataset(filename_train_data)\n","val = dataset(filename_validation_data)\n","\n","\n","#=============================================================\n","# Construimos los dataloaders para entrenamiento y validación\n","#=============================================================\n","train_data = DataLoader(trn, batch_size=BATCH_SIZE, shuffle=True)\n","validation_data = DataLoader(val, batch_size=BATCH_SIZE, shuffle=False)\n","\n","\n","#=============================================\n","# Inicializamos el modelo\n","#=============================================\n","modelo = model(n_features=2, n_inputs=2, n_outputs=1)\n","modelo.to(device)\n","\n","\n","#=============================================\n","# Definimos la función de costo a utilizar\n","#=============================================\n","loss_function = nn.MSELoss(reduction='mean').to(device)\n","\n","\n","#=============================================\n","# Definimos el optimizador a utilizar\n","# > 3er paso del algoritmo de retropropagación\n","#=============================================\n","optimizer = optim.SGD(modelo.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)"]},{"cell_type":"markdown","id":"4799c811-9ee7-4d0a-8ae9-f376129f4930","metadata":{"tags":[],"id":"4799c811-9ee7-4d0a-8ae9-f376129f4930"},"source":["## ENTRENAMIENTO DEL MODELO"]},{"cell_type":"code","execution_count":null,"id":"21313ae0-3004-4a9c-8e43-0964a335d975","metadata":{"tags":[],"id":"21313ae0-3004-4a9c-8e43-0964a335d975"},"outputs":[],"source":["error = []  # Inicializo estructura para almacenar\n","            # los errores en el tiempo\n","accuracy = []  # Inicializo estructura para almacenar\n","               # el accuracy en el tiempo\n","\n","STOP = False\n","counter = 0\n","\n","best_model = None\n","best_model_weights = None\n","\n","#===============================================================\n","while (epoca < MAX_EPOCAS) and (not STOP):\n","\n","    epoca += 1\n","\n","    #----------------------\n","    # ENTRENAMIENTO\n","    #----------------------\n","    _,modelo = train_step(modelo, train_data, loss_function, optimizer, device)\n","\n","    #----------------------\n","    # VALIDACION\n","    #----------------------\n","    e,Y,Yp = predict_step(modelo, validation_data, loss_function, device)\n","\n","    acc = torch.sum(torch.sign(Yp) == torch.sign(Y))/ len(Y)\n","\n","    #----------------------\n","    # ALMACENO MEDIDAS\n","    #----------------------\n","    error.append(e)\n","    accuracy.append(acc)\n","\n","    #-----------------------------------------------\n","    # CRITERIO DE CORTE Y ALMACENAMIENTO DEL MODELO\n","    #-----------------------------------------------\n","    if (e < MIN_ERROR):\n","        MIN_ERROR = e\n","        counter = 0\n","\n","        #·······················\n","        # Almaceno el modelo\n","        #·······················\n","        best_model = deepcopy(modelo)  # Genero una copia independiente\n","        best_model_weights = best_model.state_dict()\n","\n","    else:\n","        counter += 1\n","        if counter > PATIENCE:\n","            STOP = True\n","\n","    #--------------------------------------------\n","    # MUESTRO REPORTE POR PANTALLA (POR EPOCA)\n","    #--------------------------------------------\n","    if (epoca % 5) == 0:\n","        print(f'Epoca: {epoca} -- Error: {e:.4}\\t--\\tTasa acierto [val]: {acc:.4}\\n')\n","#===============================================================\n","\n","#--------------------------------------------\n","# MUESTRO REPORTE POR PANTALLA (FINAL)\n","#--------------------------------------------\n","print('='*79)\n","print(f'FINAL -- Epoca: {epoca} -- Error: {e:.4}\\t--\\tTasa acierto [val]: {acc:.4}')\n","print('='*79)\n","\n","#-----------------------------\n","# GUARDO MEJOR MODELO A DISCO\n","#-----------------------------\n","torch.save(best_model,\n","           'best_model.pt',\n","           _use_new_zipfile_serialization=True)\n","\n","#----------------------------------------------\n","# GUARDAMOS LOS PESOS DEL MEJOR MODELO A DISCO\n","#----------------------------------------------\n","torch.save(best_model.state_dict(),\n","           'best_model_state_dict.pt',\n","           _use_new_zipfile_serialization=True)"]},{"cell_type":"markdown","id":"ec22aa64-3830-4e57-a508-60b1d3d463e8","metadata":{"tags":[],"id":"ec22aa64-3830-4e57-a508-60b1d3d463e8"},"source":["## GRAFICAMOS LAS SALIDAS"]},{"cell_type":"code","execution_count":null,"id":"5f97e0b4-52a6-4e93-83c9-3bfefe583654","metadata":{"tags":[],"id":"5f97e0b4-52a6-4e93-83c9-3bfefe583654"},"outputs":[],"source":["fig, ax = plt.subplots(1, 3, figsize=(30,6))\n","\n","epocas = np.arange(epoca)\n","\n","# ERROR\n","ax[0].plot(epocas, error, 'o-r', lw=2)\n","ax[0].grid(True)\n","ax[0].set_xlim(0,MAX_EPOCAS)\n","ax[0].set_xlabel('Epocas', fontsize=12)\n","ax[0].set_ylabel('MSE', fontsize=12)\n","\n","# ACC\n","ax[1].plot(epocas, accuracy, 'o-b', lw=2)\n","ax[1].grid(True)\n","ax[1].set_xlim(0,MAX_EPOCAS)\n","ax[1].set_xlabel('Epocas', fontsize=12)\n","ax[1].set_ylabel('Acc', fontsize=12)\n","\n","# CLASIFICACION\n","C = []\n","for i in range(len(Y)):\n","\n","    if (torch.sign(Y[i]) == torch.sign(Yp[i])) and (torch.sign(Y[i]) == 1):\n","        C.append('blue')\n","    if (torch.sign(Y[i]) == torch.sign(Yp[i])) and (torch.sign(Y[i]) == -1):\n","        C.append('red')\n","    if (torch.sign(Y[i]) != torch.sign(Yp[i])) and (torch.sign(Y[i]) == 1):\n","        C.append('cyan')\n","    if (torch.sign(Y[i]) != torch.sign(Yp[i])) and (torch.sign(Y[i]) == -1):\n","        C.append('magenta')\n","\n","ax[2].scatter(validation_data.dataset.x[:,0], validation_data.dataset.x[:,1], 20, C)\n","ax[2].set_xlim(-1.1,1.1)\n","ax[2].set_ylim(-1.1,1.1)\n","ax[2].set_xlabel('X1', fontsize=14)\n","ax[2].set_ylabel('X2', fontsize=14)\n","ax[2].grid(True)\n","\n","# CONSTRUCCION DE LA FRONTERA DE DECISION\n","x = torch.tensor([-1.5, 1.5])\n","W1 = modelo.layer1.weight[0,:].flatten().detach().cpu()\n","B1 = modelo.layer1.bias[0].detach().cpu()\n","b1 = -B1/W1[1]\n","m1 = W1[0]/W1[1]\n","\n","W2 = modelo.layer1.weight[1,:].flatten().detach().cpu()\n","B2 = modelo.layer1.bias[1].detach().cpu()\n","b2 = -B2/W2[1]\n","m2 = W2[0]/W2[1]\n","\n","ax[2].plot(x, b1 - m1 * x, ':k', lw=2)\n","ax[2].plot(x, b2 - m2 * x, ':k', lw=2)\n","ax[2].set_xlim(-1.1,1.1)\n","ax[2].set_ylim(-1.1,1.1)\n","ax[2].grid(True)"]},{"cell_type":"markdown","id":"0d25b98b-59e1-4a45-9318-36fd7e622baf","metadata":{"id":"0d25b98b-59e1-4a45-9318-36fd7e622baf"},"source":["---"]},{"cell_type":"markdown","id":"6527b157-f89d-4fd7-a7d1-e3a8fbc2d16f","metadata":{"tags":[],"id":"6527b157-f89d-4fd7-a7d1-e3a8fbc2d16f"},"source":["## LECTURA DE DATOS DE EVALUACION"]},{"cell_type":"code","execution_count":null,"id":"90041501-1f0b-4fc5-80b2-d9dfc6e8cad2","metadata":{"tags":[],"id":"90041501-1f0b-4fc5-80b2-d9dfc6e8cad2"},"outputs":[],"source":["#=====================================\n","# LEVANTAMOS DE DISCO EL MEJOR MODELO\n","#=====================================\n","\n","del modelo  # Eliminamos de memoria\n","            # para asegurarnos de usar\n","            # el modelo guardado en disco\n","\n","#--------------------------------------\n","# Modelo completo (archivo binario)\n","#--------------------------------------\n","modelo = torch.load('best_model.pt')\n","\n","#-----------------------\n","# A partir de los pesos\n","#-----------------------\n","#best_model = torch.load('best_model_state_dict.pt')\n","#modelo = MODELO(n_features=2, n_inputs=2, n_outputs=1)\n","#modelo.load_state_dict(best_model)\n","#modelo.to(device)"]},{"cell_type":"code","execution_count":null,"id":"b182dec5-bebf-46b6-9d68-4c6487d31e12","metadata":{"tags":[],"id":"b182dec5-bebf-46b6-9d68-4c6487d31e12"},"outputs":[],"source":["#=====================================\n","# CONSTRUIMOS EL DATASET PARA TEST\n","#=====================================\n","tst = dataset(filename_test_data)\n","\n","test_data = DataLoader(tst, batch_size=BATCH_SIZE, shuffle=False)\n","\n","#=====================================\n","# EVALUAMOS EL MODELO ENTRENADO\n","#=====================================\n","error,Y,Yp = predict_step(modelo, test_data, loss_function, device)\n","\n","acc = torch.sum(torch.sign(Yp) == torch.sign(Y))/ len(Y)\n","\n","print(f'\\nTasa acierto [test]: {acc:.4}\\n')"]},{"cell_type":"markdown","id":"f515442f-8b82-4f8b-8104-42d2e814b77c","metadata":{"tags":[],"id":"f515442f-8b82-4f8b-8104-42d2e814b77c"},"source":["## GRAFICAMOS LAS SALIDAS"]},{"cell_type":"code","execution_count":null,"id":"4bf57847-b232-4137-85d4-a44710f7e748","metadata":{"tags":[],"id":"4bf57847-b232-4137-85d4-a44710f7e748"},"outputs":[],"source":["fig, ax = plt.subplots(1, 1, figsize=(10,6))\n","\n","# CLASIFICACION\n","C = []\n","for i in range(len(Y)):\n","\n","    if (torch.sign(Y[i]) == torch.sign(Yp[i])) and (torch.sign(Y[i]) == 1):\n","        C.append('blue')\n","    if (torch.sign(Y[i]) == torch.sign(Yp[i])) and (torch.sign(Y[i]) == -1):\n","        C.append('red')\n","    if (torch.sign(Y[i]) != torch.sign(Yp[i])) and (torch.sign(Y[i]) == 1):\n","        C.append('cyan')\n","    if (torch.sign(Y[i]) != torch.sign(Yp[i])) and (torch.sign(Y[i]) == -1):\n","        C.append('magenta')\n","\n","ax.scatter(test_data.dataset.x[:,0], test_data.dataset.x[:,1], 20, C)\n","ax.set_xlim(-1.1,1.1)\n","ax.set_ylim(-1.1,1.1)\n","ax.set_xlabel('X1', fontsize=14)\n","ax.set_ylabel('X2', fontsize=14)\n","ax.grid(True)\n","\n","# CONSTRUCCION DE LA FRONTERA DE DECISION\n","x = torch.tensor([-1.5, 1.5])\n","W1 = modelo.layer1.weight[0,:].flatten().detach().cpu()\n","B1 = modelo.layer1.bias[0].detach().cpu()\n","b1 = -B1/W1[1]\n","m1 = W1[0]/W1[1]\n","\n","W2 = modelo.layer1.weight[1,:].flatten().detach().cpu()\n","B2 = modelo.layer1.bias[1].detach().cpu()\n","b2 = -B2/W2[1]\n","m2 = W2[0]/W2[1]\n","\n","ax.plot(x, b1 - m1 * x, ':k', lw=2)\n","ax.plot(x, b2 - m2 * x, ':k', lw=2)\n","ax.set_xlim(-1.1,1.1)\n","ax.set_ylim(-1.1,1.1)\n","ax.grid(True)"]},{"cell_type":"code","execution_count":null,"id":"2b74f118-9b78-44c2-b852-927b7ebf8bf6","metadata":{"id":"2b74f118-9b78-44c2-b852-927b7ebf8bf6"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}